{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain - Primeros Pasos\n",
    "\n",
    "Este notebook tiene como finalidad demostrar la funcionalidad b谩sica de LangChain con ejemplos claros y f谩ciles de aplicar.\n",
    "\n",
    "## Instalaci贸n\n",
    "\n",
    "Primero vamos a preparar todo lo necesario para lograr hacer funcionar nuestras aplicaciones con LangChain.\n",
    "\n",
    "## Enlaces para obtener API Keys\n",
    "\n",
    "### OpenAI API Key\n",
    "Para obtener tu clave de API de OpenAI:\n",
    "- **Enlace**: [https://platform.openai.com/api-keys](https://platform.openai.com/api-keys)\n",
    "- **Pasos**:\n",
    "  1. Crea una cuenta en OpenAI o inicia sesi贸n\n",
    "  2. Ve a la secci贸n \"API Keys\"\n",
    "  3. Haz clic en \"Create new secret key\"\n",
    "  4. Copia y guarda la clave de forma segura\n",
    "\n",
    "### Google AI Studio API Key (Gemini)\n",
    "Para obtener tu clave de API de Google AI:\n",
    "- **Enlace**: [https://aistudio.google.com/app/apikey](https://aistudio.google.com/app/apikey)\n",
    "- **Pasos**:\n",
    "  1. Inicia sesi贸n con tu cuenta de Google\n",
    "  2. Haz clic en \"Create API Key\"\n",
    "  3. Selecciona un proyecto de Google Cloud o crea uno nuevo\n",
    "  4. Copia y guarda la clave de forma segura\n",
    "\n",
    "### Configuraci贸n de variables de entorno\n",
    "\n",
    "Crea un archivo `.env` en tu proyecto:\n",
    "\n",
    "```env\n",
    "OPENAI_API_KEY=tu_clave_openai_aqui\n",
    "GOOGLE_API_KEY=tu_clave_google_aqui\n",
    "```\n",
    "\n",
    "\n",
    "## Notas importantes\n",
    "\n",
    "- **Seguridad**: Nunca compartas tus API keys p煤blicamente\n",
    "- **L铆mites**: Revisa los l铆mites de uso de cada API\n",
    "- **Costos**: Ten en cuenta que estas APIs pueden tener costos asociados\n",
    "- **Documentaci贸n**: Consulta la documentaci贸n oficial de cada proveedor para m谩s detalles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Antes vs Despu茅s de LangChain\n",
    "\n",
    "#### Antes de LangChain\n",
    "```python\n",
    "# C贸digo complejo y espec铆fico para cada proveedor\n",
    "import openai\n",
    "import anthropic\n",
    "\n",
    "# Configuraci贸n manual para cada API\n",
    "openai.api_key = \"tu-api-key\"\n",
    "client = anthropic.Client(api_key=\"otra-api-key\")\n",
    "\n",
    "# Gesti贸n manual de conversaciones\n",
    "conversation_history = []\n",
    "\n",
    "def chat_with_openai(message):\n",
    "    conversation_history.append({\"role\": \"user\", \"content\": message})\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=conversation_history\n",
    "    )\n",
    "    # M谩s c贸digo para procesar respuesta...\n",
    "```\n",
    "\n",
    "#### Con LangChain\n",
    "```python\n",
    "# C贸digo simple y unificado\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "# Configuraci贸n simple\n",
    "llm = OpenAI(temperature=0.7)\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(llm=llm, memory=memory)\n",
    "\n",
    "# Uso directo\n",
    "response = conversation.predict(input=\"Hola, 驴c贸mo est谩s?\")\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': '        To get started, get an GOOGLE_API_KEY and enter it in the first step    '}\n",
      "{'error': '        To get started, get an OPENAI_API_KEY and enter it in the first step    '}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['GOOGLE_API_KEY'] = 'TODO';\n",
    "os.environ['OPENAI_API_KEY'] = 'TODO';\n",
    "\n",
    "\n",
    "if os.environ[\"GOOGLE_API_KEY\"] == 'TODO':\n",
    "    print({ \"error\": '''\n",
    "        To get started, get an GOOGLE_API_KEY and enter it in the first step\n",
    "    '''.replace('\\n', '') })\n",
    "if os.environ[\"OPENAI_API_KEY\"] == 'TODO':\n",
    "    print({ \"error\": '''\n",
    "        To get started, get an OPENAI_API_KEY and enter it in the first step\n",
    "    '''.replace('\\n', '') })\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "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\n",
      "AIzaSyAM4-undhYVmimPfrkZtP6dVDuq3PINQSI\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv\n",
    "\n",
    "#Imprimir OPENAI_API_KEY usando loadenv \n",
    "#Limpiar las variablas para que no digna TODO Y leer desde el .env\n",
    "\n",
    "\n",
    "import os \n",
    "from dotenv import load_dotenv \n",
    "\n",
    "load_dotenv(dotenv_path='.env',override=True)\n",
    "\n",
    "print(os.getenv('OPENAI_API_KEY'))\n",
    "print(os.getenv('GOOGLE_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: pydantic 2.11.5\n",
      "Uninstalling pydantic-2.11.5:\n",
      "  Successfully uninstalled pydantic-2.11.5\n",
      "Found existing installation: langchain 0.3.25\n",
      "Uninstalling langchain-0.3.25:\n",
      "  Successfully uninstalled langchain-0.3.25\n",
      "Found existing installation: langchain-core 0.3.64\n",
      "Uninstalling langchain-core-0.3.64:\n",
      "  Successfully uninstalled langchain-core-0.3.64\n",
      "Found existing installation: langchain-openai 0.3.21\n",
      "Uninstalling langchain-openai-0.3.21:\n",
      "  Successfully uninstalled langchain-openai-0.3.21\n",
      "Found existing installation: langchain-community 0.3.24\n",
      "Uninstalling langchain-community-0.3.24:\n",
      "  Successfully uninstalled langchain-community-0.3.24\n",
      "Collecting langchain-openai\n",
      "  Using cached langchain_openai-0.3.21-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.64 (from langchain-openai)\n",
      "  Using cached langchain_core-0.3.64-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.68.2 in ./.venv/lib/python3.11/site-packages (from langchain-openai) (1.84.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in ./.venv/lib/python3.11/site-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.3.45 in ./.venv/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.64->langchain-openai) (0.3.45)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./.venv/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.64->langchain-openai) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.64->langchain-openai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.64->langchain-openai) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./.venv/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.64->langchain-openai) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./.venv/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.64->langchain-openai) (4.14.0)\n",
      "Collecting pydantic>=2.7.4 (from langchain-core<1.0.0,>=0.3.64->langchain-openai)\n",
      "  Using cached pydantic-2.11.5-py3-none-any.whl.metadata (67 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./.venv/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in ./.venv/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain-openai) (3.10)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.64->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.64->langchain-openai) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./.venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.64->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./.venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.64->langchain-openai) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.64->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.64->langchain-openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.64->langchain-openai) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.4.0)\n",
      "Using cached langchain_openai-0.3.21-py3-none-any.whl (65 kB)\n",
      "Using cached langchain_core-0.3.64-py3-none-any.whl (438 kB)\n",
      "Using cached pydantic-2.11.5-py3-none-any.whl (444 kB)\n",
      "Installing collected packages: pydantic, langchain-core, langchain-openai\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-anthropic 0.1.16 requires langchain-core<0.3,>=0.2.10, but you have langchain-core 0.3.64 which is incompatible.\n",
      "langchain-google-genai 1.0.8 requires langchain-core<0.3,>=0.2.17, but you have langchain-core 0.3.64 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed langchain-core-0.3.64 langchain-openai-0.3.21 pydantic-2.11.5\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: langchain-anthropic in ./.venv/lib/python3.11/site-packages (0.1.16)\n",
      "Requirement already satisfied: anthropic<1,>=0.28.0 in ./.venv/lib/python3.11/site-packages (from langchain-anthropic) (0.53.0)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in ./.venv/lib/python3.11/site-packages (from langchain-anthropic) (0.7.1)\n",
      "Collecting langchain-core<0.3,>=0.2.10 (from langchain-anthropic)\n",
      "  Using cached langchain_core-0.2.43-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.11/site-packages (from anthropic<1,>=0.28.0->langchain-anthropic) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.11/site-packages (from anthropic<1,>=0.28.0->langchain-anthropic) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in ./.venv/lib/python3.11/site-packages (from anthropic<1,>=0.28.0->langchain-anthropic) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.11/site-packages (from anthropic<1,>=0.28.0->langchain-anthropic) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.venv/lib/python3.11/site-packages (from anthropic<1,>=0.28.0->langchain-anthropic) (2.11.5)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.11/site-packages (from anthropic<1,>=0.28.0->langchain-anthropic) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in ./.venv/lib/python3.11/site-packages (from anthropic<1,>=0.28.0->langchain-anthropic) (4.14.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.10->langchain-anthropic) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.10->langchain-anthropic) (1.33)\n",
      "Collecting langsmith<0.2.0,>=0.1.112 (from langchain-core<0.3,>=0.2.10->langchain-anthropic)\n",
      "  Using cached langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./.venv/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.10->langchain-anthropic) (24.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./.venv/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.10->langchain-anthropic) (8.5.0)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.11/site-packages (from anyio<5,>=3.5.0->anthropic<1,>=0.28.0->langchain-anthropic) (3.10)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.25.0->anthropic<1,>=0.28.0->langchain-anthropic) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.25.0->anthropic<1,>=0.28.0->langchain-anthropic) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic<1,>=0.28.0->langchain-anthropic) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.10->langchain-anthropic) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2.10->langchain-anthropic) (3.10.18)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2.10->langchain-anthropic) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./.venv/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2.10->langchain-anthropic) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->anthropic<1,>=0.28.0->langchain-anthropic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->anthropic<1,>=0.28.0->langchain-anthropic) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->anthropic<1,>=0.28.0->langchain-anthropic) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2.10->langchain-anthropic) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2.10->langchain-anthropic) (2.4.0)\n",
      "Using cached langchain_core-0.2.43-py3-none-any.whl (397 kB)\n",
      "Using cached langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
      "Installing collected packages: langsmith, langchain-core\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.3.45\n",
      "    Uninstalling langsmith-0.3.45:\n",
      "      Successfully uninstalled langsmith-0.3.45\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.64\n",
      "    Uninstalling langchain-core-0.3.64:\n",
      "      Successfully uninstalled langchain-core-0.3.64\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langgraph-prebuilt 0.2.2 requires langchain-core>=0.3.22, but you have langchain-core 0.2.43 which is incompatible.\n",
      "langchain-openai 0.3.21 requires langchain-core<1.0.0,>=0.3.64, but you have langchain-core 0.2.43 which is incompatible.\n",
      "langchain-text-splitters 0.3.8 requires langchain-core<1.0.0,>=0.3.51, but you have langchain-core 0.2.43 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed langchain-core-0.2.43 langsmith-0.1.147\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: langchain-google-genai in ./.venv/lib/python3.11/site-packages (1.0.8)\n",
      "Requirement already satisfied: google-generativeai<0.8.0,>=0.7.0 in ./.venv/lib/python3.11/site-packages (from langchain-google-genai) (0.7.2)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.2.17 in ./.venv/lib/python3.11/site-packages (from langchain-google-genai) (0.2.43)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.6 in ./.venv/lib/python3.11/site-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.6.6)\n",
      "Requirement already satisfied: google-api-core in ./.venv/lib/python3.11/site-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.25.0)\n",
      "Requirement already satisfied: google-api-python-client in ./.venv/lib/python3.11/site-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.171.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in ./.venv/lib/python3.11/site-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.40.3)\n",
      "Requirement already satisfied: protobuf in ./.venv/lib/python3.11/site-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.25.8)\n",
      "Requirement already satisfied: pydantic in ./.venv/lib/python3.11/site-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.11.5)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.11/site-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.11/site-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.14.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in ./.venv/lib/python3.11/site-packages (from google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.26.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.17->langchain-google-genai) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.17->langchain-google-genai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in ./.venv/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.17->langchain-google-genai) (0.1.147)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./.venv/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.17->langchain-google-genai) (24.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./.venv/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.17->langchain-google-genai) (8.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in ./.venv/lib/python3.11/site-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in ./.venv/lib/python3.11/site-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./.venv/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.9.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.17->langchain-google-genai) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2.17->langchain-google-genai) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2.17->langchain-google-genai) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./.venv/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2.17->langchain-google-genai) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.11/site-packages (from pydantic->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.11/site-packages (from pydantic->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.11/site-packages (from pydantic->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.4.1)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in ./.venv/lib/python3.11/site-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in ./.venv/lib/python3.11/site-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in ./.venv/lib/python3.11/site-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.2.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in ./.venv/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.73.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in ./.venv/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.62.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in ./.venv/lib/python3.11/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (3.2.3)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2.17->langchain-google-genai) (4.9.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2.17->langchain-google-genai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2.17->langchain-google-genai) (1.0.9)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2.17->langchain-google-genai) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2.17->langchain-google-genai) (0.16.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in ./.venv/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.4.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2.17->langchain-google-genai) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: langchain-core in ./.venv/lib/python3.11/site-packages (0.2.43)\n",
      "Collecting langchain-core\n",
      "  Using cached langchain_core-0.3.64-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langsmith<0.4,>=0.3.45 (from langchain-core)\n",
      "  Using cached langsmith-0.3.45-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./.venv/lib/python3.11/site-packages (from langchain-core) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.11/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.11/site-packages (from langchain-core) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./.venv/lib/python3.11/site-packages (from langchain-core) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./.venv/lib/python3.11/site-packages (from langchain-core) (4.14.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in ./.venv/lib/python3.11/site-packages (from langchain-core) (2.11.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.3.45->langchain-core) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.3.45->langchain-core) (3.10.18)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.3.45->langchain-core) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./.venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.3.45->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./.venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.3.45->langchain-core) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core) (0.4.1)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core) (4.9.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core) (1.0.9)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core) (0.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.4,>=0.3.45->langchain-core) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.4,>=0.3.45->langchain-core) (2.4.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core) (1.3.1)\n",
      "Using cached langchain_core-0.3.64-py3-none-any.whl (438 kB)\n",
      "Using cached langsmith-0.3.45-py3-none-any.whl (363 kB)\n",
      "Installing collected packages: langsmith, langchain-core\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.1.147\n",
      "    Uninstalling langsmith-0.1.147:\n",
      "      Successfully uninstalled langsmith-0.1.147\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.2.43\n",
      "    Uninstalling langchain-core-0.2.43:\n",
      "      Successfully uninstalled langchain-core-0.2.43\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-anthropic 0.1.16 requires langchain-core<0.3,>=0.2.10, but you have langchain-core 0.3.64 which is incompatible.\n",
      "langchain-google-genai 1.0.8 requires langchain-core<0.3,>=0.2.17, but you have langchain-core 0.3.64 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed langchain-core-0.3.64 langsmith-0.3.45\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting langchain\n",
      "  Using cached langchain-0.3.25-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: langchain-openai in ./.venv/lib/python3.11/site-packages (0.3.21)\n",
      "Requirement already satisfied: pydantic in ./.venv/lib/python3.11/site-packages (2.11.5)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in ./.venv/lib/python3.11/site-packages (from langchain) (0.3.64)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in ./.venv/lib/python3.11/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in ./.venv/lib/python3.11/site-packages (from langchain) (0.3.45)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.venv/lib/python3.11/site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.11/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.11/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.68.2 in ./.venv/lib/python3.11/site-packages (from langchain-openai) (1.84.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in ./.venv/lib/python3.11/site-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.11/site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.11/site-packages (from pydantic) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in ./.venv/lib/python3.11/site-packages (from pydantic) (4.14.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.11/site-packages (from pydantic) (0.4.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./.venv/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./.venv/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./.venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./.venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
      "Requirement already satisfied: greenlet>=1 in ./.venv/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./.venv/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
      "Using cached langchain-0.3.25-py3-none-any.whl (1.0 MB)\n",
      "Installing collected packages: langchain\n",
      "Successfully installed langchain-0.3.25\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y pydantic langchain langchain-core langchain-openai langchain-community\n",
    "!pip install  langchain-openai\n",
    "!pip install langchain-anthropic\n",
    "!pip install langchain-google-genai\n",
    "!pip install -U langchain-core\n",
    "!pip install --upgrade langchain langchain-openai pydantic\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primeros pasos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos las librer铆as necesarias para invocar los modelos de google y openai\n",
    "# Docs https://python.langchain.com/docs/integrations/chat/google_generative_ai/\n",
    "# Docs https://python.langchain.com/docs/integrations/chat/openai/\n",
    "\n",
    "#from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "#Creamos una instancia del modelo de google\n",
    "#google_llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\",temperature=0)\n",
    "openai_llm = ChatOpenAI( model=\"gpt-4o\",\n",
    "    temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='隆Claro! Aqu铆 tienes uno:\\n\\n驴Por qu茅 los p谩jaros no usan Facebook?\\n\\nPorque ya tienen Twitter.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 13, 'total_tokens': 35, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_55d88aaf2f', 'id': 'chatcmpl-Bgfs9S0FWighocvsg35D1flNSzl7i', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--bae5485b-9270-46e5-8dda-02dc6df16fea-0', usage_metadata={'input_tokens': 13, 'output_tokens': 22, 'total_tokens': 35, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Creamos un prompt solo para probar la funcionalidad \n",
    "#google_llm.invoke('Cuentame un chiste')\n",
    "openai_llm.invoke('Cuentame un chiste')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='隆Claro! Aqu铆 tienes uno:\\n\\n驴Por qu茅 los p谩jaros no usan Facebook?\\n\\nPorque ya tienen Twitter. ' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 13, 'total_tokens': 38, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'id': 'chatcmpl-BgfsEUx4jrDe11SnGpwFhuSCLTK80', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--a5cd0e22-d79f-4539-ae58-a5ba3eb42f01-0' usage_metadata={'input_tokens': 13, 'output_tokens': 25, 'total_tokens': 38, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'隆Claro! Aqu铆 tienes uno:\\n\\n驴Por qu茅 los p谩jaros no usan Facebook?\\n\\nPorque ya tienen Twitter. '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_reponse = openai_llm.invoke('Cuentame un chiste')\n",
    "print(llm_reponse)\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser=StrOutputParser()\n",
    "output_parser.invoke(llm_reponse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mi primera chain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'隆Claro! Aqu铆 tienes uno:\\n\\n驴Por qu茅 los p谩jaros no usan Facebook?\\n\\nPorque ya tienen Twitter.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain= openai_llm | output_parser\n",
    "chain.invoke(\"Cuentame un chiste\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Simple Chain - Procesamiento Lineal Directo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Asunto: Actualizaci贸n Detallada de Proyectos Activos y Otras Iniciativas\\n\\nEstimado equipo directivo,\\n\\nEspero que se encuentren bien. Me complace compartir con ustedes un resumen detallado del estado actual de nuestros proyectos activos, as铆 como algunas iniciativas estrat茅gicas y operativas clave.\\n\\n**Proyecto Nebula (Aplicaci贸n M贸vil B2C)**\\n- **ID:** P-003\\n- **Liderazgo:** Carolina Velez\\n- **Objetivo:** Lanzar una aplicaci贸n m贸vil nativa para iOS y Android, con la meta de alcanzar 50,000 descargas y una calificaci贸n de 4.5 estrellas en los primeros seis meses.\\n- **Progreso Actual:**\\n  - Definici贸n del MVP completada, utilizando React Native para el desarrollo multiplataforma.\\n  - Avance semanal documentado desde la configuraci贸n del entorno de desarrollo hasta las pruebas iniciales en TestFlight y Open Testing.\\n- **Backlog de Funcionalidades (Post-MVP):** Incluye modo offline, mensajer铆a directa, integraci贸n con calendario, entre otros.\\n- **Bugs Reportados (Alpha Interna):** Se han identificado y priorizado varios bugs, siendo el m谩s cr铆tico el cierre inesperado de la aplicaci贸n al abrir notificaciones push.\\n\\n**Proyecto Andr贸meda (Migraci贸n a Kubernetes)**\\n- **ID:** P-004\\n- **Liderazgo:** David Campos\\n- **Objetivo:** Migrar servicios monol铆ticos a microservicios en GKE, con la meta de reducir el tiempo de despliegue en un 80% y mejorar la disponibilidad al 99.99%.\\n- **Progreso Actual:**\\n  - Configuraci贸n inicial del cluster de GKE y despliegue de los primeros microservicios.\\n  - Monitoreo implementado con Prometheus y Grafana.\\n- **Plan de Migraci贸n de Servicios Restantes:** Incluye servicios cr铆ticos como notificaciones, reportes y autenticaci贸n.\\n\\n**Proyecto Tit谩n (Plataforma Unificada)**\\n- **ID:** P-001\\n- **Liderazgo:** Ricardo Morales\\n- **Objetivo:** Unificar los sistemas Legacy en una nueva plataforma SaaS antes de fin de a帽o, con mejoras significativas en costos y experiencia de usuario.\\n- **Progreso Actual:**\\n  - Completado el kick-off y avances significativos en m贸dulos clave como autenticaci贸n y dashboard.\\n  - Se han identificado y est谩n en mitigaci贸n cuellos de botella t茅cnicos.\\n- **Backlog y Bugs Cr铆ticos:** M贸dulo de facturaci贸n, sistema de notificaciones y exportaci贸n de datos, entre otros. Bugs cr铆ticos incluyen fuga de memoria y problemas de exportaci贸n a PDF.\\n\\n**Proyecto Quasar (An谩lisis Predictivo)**\\n- **ID:** P-002\\n- **Liderazgo:** M贸nica Salas\\n- **Objetivo:** Desarrollar un motor predictivo para identificar el riesgo de abandono de clientes con una precisi贸n del 75%.\\n- **Progreso Actual:**\\n  - Modelos iniciales entrenados y superaci贸n del objetivo de precisi贸n.\\n  - En curso la planificaci贸n para el despliegue de modelos.\\n\\n**Iniciativas Estrat茅gicas y Operativas:**\\n- **Reuniones Clave:** Se han discutido desaf铆os y estrategias en el comit茅 de direcci贸n, con acciones asignadas a los responsables.\\n- **Tickets de Soporte y Feedback de Clientes:** Se est谩n priorizando los tickets de alta criticidad para garantizar la satisfacci贸n del cliente.\\n- **Nuevas Ideas:** Se est谩n explorando varios proyectos innovadores, como \"Project Spark\" para micro-aprendizaje y \"Project Prism\" para visualizaci贸n de datos.\\n\\nAdjunto encontrar谩n los detalles completos de cada secci贸n mencionada. Agradezco su atenci贸n y quedo a disposici贸n para cualquier consulta o discusi贸n adicional.\\n\\nAtentamente,\\n\\n[Tu Nombre]  \\n[Tu Cargo]  \\n[Tu Empresa]  \\n[Tel茅fono de Contacto]  \\n[Correo Electr贸nico]'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "# Leer notas informales de un cliente de un txt \n",
    "with open(\"data/notas.txt\", \"r\") as f:\n",
    "    notas = f.read()\n",
    "destinatario = \"equipo directivo\"\n",
    "tono = \"formal\"\n",
    "\n",
    "# Caso: Convertir notas informales en emails profesionales\n",
    "email_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Convierte estas notas informales en un email profesional:\\n\"\n",
    "    \"Notas: {notas}\\n\"\n",
    "    \"Destinatario: {destinatario}\\n\"\n",
    "    \"Tono: {tono}\"\n",
    "    \n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# Simple Chain - Una entrada, una salida\n",
    "email_chain = email_prompt | llm | parser\n",
    "\n",
    "# Uso\n",
    "resultado = email_chain.invoke({\n",
    "    \"Fecha\": \"Reuni贸n ma帽ana 10am\",\n",
    "    \"notas\": notas,\n",
    "    \"destinatario\": destinatario,\n",
    "    \"tono\": tono\n",
    "})\n",
    "\n",
    "resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Sequential Chain - \"Paso a paso hacia la excelencia\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "import os \n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "# Read file csv in text plain \n",
    "\n",
    "\n",
    "\n",
    "financial_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    **Rol:** Eres un Analista Financiero Cuantitativo Senior.\n",
    "\n",
    "    **Tarea:** Analiza los siguientes datos hist贸ricos de precios de acciones. Calcula los indicadores clave y resume las tendencias de mercado observadas en el per铆odo.\n",
    "\n",
    "    **Instrucciones:**\n",
    "    1.  Revisa los datos de mercado proporcionados.\n",
    "    2.  Calcula y presenta las siguientes m茅tricas clave:\n",
    "        - Rango de precios (Precio de Cierre M铆nimo y M谩ximo).\n",
    "        - Precio de Cierre Promedio.\n",
    "        - Volumen de Transacciones Promedio.\n",
    "        - Volatilidad hist贸rica (desviaci贸n est谩ndar de los rendimientos diarios del Precio de Cierre).\n",
    "    3.  Describe las principales tendencias observadas:\n",
    "        - Identifica el sentimiento general del mercado (alcista/bajista) durante este per铆odo.\n",
    "        - Se帽ala los per铆odos de crecimiento m谩s acelerado y las ca铆das m谩s pronunciadas.\n",
    "        - Comenta la relaci贸n entre el volumen y los movimientos de precios (ej. 驴Los grandes aumentos de precio fueron acompa帽ados de un alto volumen?).\n",
    "    4.  Estructura tu respuesta de forma clara y concisa usando Markdown.\n",
    "\n",
    "    **Datos de Mercado (financial_statements):**\n",
    "    ```csv\n",
    "    {financial_statements}\n",
    "    ```\n",
    "\n",
    "    **Salida esperada:** Un informe estructurado titulado \"An谩lisis Financiero de Mercado\".\n",
    "    ---\n",
    "    An谩lisis Financiero de Mercado:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "risk_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    **Rol:** Eres un Analista de Gesti贸n de Riesgos especializado en mercados de capital.\n",
    "\n",
    "    **Tarea:** Bas谩ndote en el an谩lisis financiero proporcionado, eval煤a y describe los principales riesgos de inversi贸n asociados con este activo.\n",
    "\n",
    "    **Instrucciones:**\n",
    "    1.  Lee el an谩lisis financiero que se te ha entregado.\n",
    "    2.  Identifica y detalla los siguientes riesgos, usando la informaci贸n del an谩lisis:\n",
    "        - **Riesgo de Volatilidad:** Usando la m茅trica de volatilidad calculada, explica si el activo es de bajo, moderado o alto riesgo. 驴Qu茅 implican las fuertes oscilaciones de precio para un inversor?\n",
    "        - **Riesgo de Mercado y Correcci贸n:** Basado en las tendencias alcistas pronunciadas, 驴existe un riesgo de \"burbuja\" o una alta probabilidad de correcci贸n de precios?\n",
    "        - **Riesgo de Liquidez:** Aunque el volumen promedio se proporciona, 驴hubo alg煤n per铆odo de volumen inusualmente bajo que pudiera indicar un riesgo de liquidez?\n",
    "    3.  Menciona expl铆citamente que este an谩lisis NO incluye riesgos fundamentales (operativos, de gesti贸n, de competencia) ya que no se proporcionaron estados financieros completos (10-K, etc.).\n",
    "    4.  Estructura tu respuesta como una evaluaci贸n de riesgos clara.\n",
    "\n",
    "    **An谩lisis Financiero Previo (financial_analysis):**\n",
    "    ```\n",
    "    {financial_analysis}\n",
    "    ```\n",
    "\n",
    "    **Salida esperada:** Un informe de riesgos titulado \"Evaluaci贸n de Riesgos de Inversi贸n\".\n",
    "    ---\n",
    "    Evaluaci贸n de Riesgos de Inversi贸n:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "valuation_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    **Rol:** Eres un banquero de inversi贸n experto en valoraci贸n de empresas.\n",
    "\n",
    "    **Tarea:** Sintetiza el an谩lisis financiero y la evaluaci贸n de riesgos para proporcionar un dictamen de valoraci贸n cualitativo sobre el activo.\n",
    "\n",
    "    **Instrucciones:**\n",
    "    1.  Considera tanto el \"An谩lisis Financiero de Mercado\" como la \"Evaluaci贸n de Riesgos de Inversi贸n\".\n",
    "    2.  Proporciona una conclusi贸n sobre el perfil del activo: 驴Es un activo de crecimiento especulativo, un activo de valor estable, etc.?\n",
    "    3.  Basado en la alta volatilidad y las tendencias, discute si la valoraci贸n parece estar impulsada por fundamentos s贸lidos (que no podemos ver) o por el sentimiento del mercado y la especulaci贸n.\n",
    "    4.  **Importante:** Comienza tu dictamen declarando las limitaciones de esta valoraci贸n. Explica que sin estados financieros completos (ingresos, beneficios, deuda, flujo de caja), es imposible realizar una valoraci贸n fundamental (ej. DCF o por m煤ltiplos). Tu valoraci贸n se basar谩 煤nicamente en el comportamiento hist贸rico del precio y los riesgos derivados de este.\n",
    "\n",
    "    **An谩lisis Financiero (financial_analysis):**\n",
    "    ```\n",
    "    {financial_analysis}\n",
    "    ```\n",
    "\n",
    "    **Evaluaci贸n de Riesgos (risk_assessment):**\n",
    "    ```\n",
    "    {risk_assessment}\n",
    "    ```\n",
    "\n",
    "    **Salida esperada:** Un dictamen de valoraci贸n titulado \"Dictamen Cualitativo de Valoraci贸n\".\n",
    "    ---\n",
    "    Dictamen Cualitativo de Valoraci贸n:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "report_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    **Rol:** Eres un Director General en una firma de consultor铆a estrat茅gica.\n",
    "\n",
    "    **Tarea:** Consolida todos los an谩lisis previos (financiero, de riesgos y de valoraci贸n) en un 煤nico resumen ejecutivo. El objetivo es que un C-level pueda entender la situaci贸n en menos de 60 segundos.\n",
    "\n",
    "    **Instrucciones:**\n",
    "    1.  Utiliza la informaci贸n de los tres documentos proporcionados.\n",
    "    2.  No introduzcas nueva informaci贸n. Tu trabajo es destilar y presentar.\n",
    "    3.  El resumen debe ser conciso, directo y utilizar vi帽etas para facilitar la lectura.\n",
    "    4.  Sigue estrictamente la siguiente estructura:\n",
    "\n",
    "        **Asunto:** Resumen Ejecutivo de Due Diligence de Activo en Mercado\n",
    "\n",
    "        **1. Conclusi贸n Financiera Clave:**\n",
    "        - Resume en 2-3 vi帽etas los hallazgos m谩s importantes del an谩lisis de mercado (ej. \"Crecimiento explosivo\", \"Alta volatilidad\", etc.).\n",
    "\n",
    "        **2. Riesgos Principales Identificados:**\n",
    "        - Resume en 2-3 vi帽etas los riesgos m谩s cr铆ticos (ej. \"Riesgo extremo de volatilidad\", \"Posible sobrevaloraci贸n especulativa\").\n",
    "\n",
    "        **3. Dictamen de Valoraci贸n:**\n",
    "        - Presenta la conclusi贸n final del dictamen de valoraci贸n en una o dos frases.\n",
    "\n",
    "        **4. Recomendaci贸n Estrat茅gica:**\n",
    "        - Basado en todo lo anterior, proporciona una recomendaci贸n final de una l铆nea (ej. \"Recomendado para inversores con alta tolerancia al riesgo en busca de crecimiento especulativo\" o \"Se recomienda cautela debido a la extrema volatilidad y posibles signos de burbuja\").\n",
    "        **5. Grafico en formato     \n",
    "    **An谩lisis Financiero (financial_analysis):**\n",
    "    ```\n",
    "    {financial_analysis}\n",
    "    ```\n",
    "\n",
    "    **Evaluaci贸n de Riesgos (risk_assessment):**\n",
    "    ```\n",
    "    {risk_assessment}\n",
    "    ```\n",
    "\n",
    "    **Dictamen de Valoraci贸n (valuation):**\n",
    "    ```\n",
    "    {valuation}\n",
    "    ```\n",
    "\n",
    "    **Salida esperada:** Un Resumen Ejecutivo.\n",
    "    ---\n",
    "    Resumen Ejecutivo:\n",
    "    \"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1749499181.576340   10561 fork_posix.cc:71] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.25-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.58 (from langchain)\n",
      "  Using cached langchain_core-0.3.64-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in ./.venv/lib/python3.11/site-packages (from langchain) (0.1.147)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./.venv/lib/python3.11/site-packages (from langchain) (2.11.5)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading sqlalchemy-2.0.41-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.11/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.11/site-packages (from langchain) (6.0.2)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Using cached langsmith-0.3.45-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./.venv/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./.venv/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./.venv/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.14.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./.venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./.venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.2.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Downloading langchain-0.3.25-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached langchain_core-0.3.64-py3-none-any.whl (438 kB)\n",
      "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Using cached langsmith-0.3.45-py3-none-any.whl (363 kB)\n",
      "Downloading sqlalchemy-2.0.41-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.2.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (585 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m585.5/585.5 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: greenlet, SQLAlchemy, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.1.147\n",
      "    Uninstalling langsmith-0.1.147:\n",
      "      Successfully uninstalled langsmith-0.1.147\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.2.43\n",
      "    Uninstalling langchain-core-0.2.43:\n",
      "      Successfully uninstalled langchain-core-0.2.43\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-openai 0.1.22 requires langchain-core<0.3.0,>=0.2.33, but you have langchain-core 0.3.64 which is incompatible.\n",
      "langchain-anthropic 0.1.16 requires langchain-core<0.3,>=0.2.10, but you have langchain-core 0.3.64 which is incompatible.\n",
      "langchain-google-genai 1.0.8 requires langchain-core<0.3,>=0.2.17, but you have langchain-core 0.3.64 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed SQLAlchemy-2.0.41 greenlet-3.2.3 langchain-0.3.25 langchain-core-0.3.64 langchain-text-splitters-0.3.8 langsmith-0.3.45\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RESUMEN EJECUTIVO ---\n",
      "**Asunto:** Resumen Ejecutivo de Due Diligence de Activo en Mercado\n",
      "\n",
      "**1. Conclusi贸n Financiera Clave:**\n",
      "- El mercado ha mostrado un crecimiento alcista pronunciado, con el precio de cierre del activo aumentando de $86 a m谩s de $705 en un a帽o.\n",
      "- Se han identificado per铆odos de crecimiento acelerado y ca铆das pronunciadas, evidenciando alta volatilidad.\n",
      "- El volumen de transacciones promedio es alto, reflejando un mercado l铆quido y activo.\n",
      "\n",
      "**2. Riesgos Principales Identificados:**\n",
      "- Existe un riesgo de volatilidad moderada a alta, con una desviaci贸n est谩ndar del 3.4%, lo que implica fluctuaciones significativas en el precio.\n",
      "- El riesgo de mercado incluye la posibilidad de una burbuja y correcciones bruscas, dados los aumentos r谩pidos y sostenidos en el precio.\n",
      "- Aunque la liquidez es generalmente alta, los inversores deben estar preparados para escenarios de alta volatilidad.\n",
      "\n",
      "**3. Dictamen de Valoraci贸n:**\n",
      "- El activo se clasifica como de crecimiento especulativo, impulsado m谩s por el sentimiento del mercado que por fundamentos s贸lidos, debido a la falta de datos financieros completos.\n",
      "\n",
      "**4. Recomendaci贸n Estrat茅gica:**\n",
      "- Recomendado para inversores con alta tolerancia al riesgo en busca de crecimiento especulativo, pero se sugiere cautela ante la posibilidad de correcci贸n del mercado y la alta volatilidad.\n"
     ]
    }
   ],
   "source": [
    "# Importa las clases necesarias\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "# Tus prompts y tu LLM ya est谩n definidos...\n",
    "# financial_prompt, risk_prompt, valuation_prompt, report_prompt, llm\n",
    "\n",
    "# --- Definici贸n de las cadenas individuales ---\n",
    "# Cada cadena se define por separado para mayor claridad.\n",
    "financial_analyzer = financial_prompt | llm | StrOutputParser()\n",
    "risk_analyzer = risk_prompt | llm | StrOutputParser()\n",
    "valuation_analyzer = valuation_prompt | llm | StrOutputParser()\n",
    "executive_summarizer = report_prompt | llm | StrOutputParser()\n",
    "\n",
    "# --- Construcci贸n de la cadena secuencial con LCEL (Forma corregida) ---\n",
    "\n",
    "# Empezamos con un \"passthrough\" que toma la entrada original\n",
    "# y le \"asigna\" el resultado del primer an谩lisis.\n",
    "full_chain = RunnablePassthrough.assign(\n",
    "    financial_analysis=financial_analyzer\n",
    ").assign(\n",
    "    risk_assessment=risk_analyzer\n",
    ").assign(\n",
    "    valuation=valuation_analyzer\n",
    ").assign(\n",
    "    executive_summary=executive_summarizer\n",
    ")\n",
    "\n",
    "# --- Ahora, la invocaci贸n funcionar谩 correctamente ---\n",
    "\n",
    "# Tus datos de entrada\n",
    "financial_statements = open(\"data/TSLA.csv\", \"r\").read() # Aseg煤rate que la ruta sea correcta\n",
    "\n",
    "input_data = {\n",
    "    \"financial_statements\": financial_statements,\n",
    "    \"company_data\": \"Informaci贸n adicional de la Tesla\"\n",
    "}\n",
    "\n",
    "# Esta l铆nea ahora funcionar谩 porque 'full_chain' es un Runnable v谩lido\n",
    "final_result = full_chain.invoke(input_data)\n",
    "\n",
    "# El resultado 'final_result' ser谩 un diccionario con todas las claves:\n",
    "# 'financial_statements', 'company_data', 'financial_analysis', 'risk_assessment', 'valuation', y 'executive_summary'\n",
    "print(\"--- RESUMEN EJECUTIVO ---\")\n",
    "print(final_result['executive_summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Router Chain - Decisiones Inteligentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clasificar_consulta(consulta: str) -> str:\n",
    "    \"\"\"\n",
    "    Clasifica la consulta en una de las categor铆as:\n",
    "    - it: Problemas t茅cnicos, computadoras, software\n",
    "    - hr: Recursos humanos, vacaciones, pol铆ticas\n",
    "    - general: Consultas generales, informaci贸n b谩sica\n",
    "    \"\"\"\n",
    "    \n",
    "    # Palabras clave para clasificaci贸n simple\n",
    "    keywords_it = [\"computadora\", \"wifi\", \"email\", \"sistema\", \"impresora\", \"red\", \"software\", \"contrase帽a\"]\n",
    "    keywords_hr = [\"vacaciones\", \"sueldo\", \"aumento\", \"pol铆ticas\", \"trabajo remoto\", \"datos bancarios\", \"contrato\"]\n",
    "    \n",
    "    consulta_lower = consulta.lower()\n",
    "    \n",
    "    # Contar coincidencias\n",
    "    it_score = sum(1 for word in keywords_it if word in consulta_lower)\n",
    "    hr_score = sum(1 for word in keywords_hr if word in consulta_lower)\n",
    "    \n",
    "    if it_score > hr_score and it_score > 0:\n",
    "        return \"it\"\n",
    "    elif hr_score > 0:\n",
    "        return \"hr\"\n",
    "    else:\n",
    "        return \"general\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Para instalar un programa nuevo:\\n\\n1. **Respuesta clara y concisa**: Aseg煤rate de tener los permisos necesarios para instalar software en tu dispositivo. Descarga el programa desde una fuente confiable y sigue las instrucciones de instalaci贸n proporcionadas. Si es necesario, reinicia tu computadora despu茅s de la instalaci贸n.\\n\\n2. **A qui茅n contactar para m谩s informaci贸n**: Si necesitas ayuda adicional o no tienes los permisos adecuados, contacta al departamento de TI de tu empresa. Ellos podr谩n guiarte a trav茅s del proceso de instalaci贸n y resolver cualquier problema que puedas encontrar.\\n\\n3. **Recursos adicionales disponibles**: Consulta la intranet de tu empresa o el portal de soporte t茅cnico para obtener gu铆as espec铆ficas de instalaci贸n o pol铆ticas de software. Tambi茅n, revisa el sitio web del proveedor del software para obtener manuales de usuario o tutoriales en l铆nea.'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnableBranch \n",
    "\n",
    "it_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Eres un especialista en soporte t茅cnico corporativo.\n",
    "    \n",
    "    Consulta: {consulta}\n",
    "    \n",
    "    Proporciona una soluci贸n t茅cnica paso a paso:\n",
    "    1. Diagn贸stico inicial\n",
    "    2. Pasos de resoluci贸n\n",
    "    3. Cu谩ndo escalar a nivel 2\n",
    "    \n",
    "    Respuesta t茅cnica:\"\"\"\n",
    ")\n",
    "\n",
    "it_chain = it_prompt | llm | StrOutputParser()\n",
    "\n",
    "#  HR Support Chain  \n",
    "hr_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Eres un especialista en Recursos Humanos.\n",
    "    \n",
    "    Consulta: {consulta}\n",
    "    \n",
    "    Proporciona informaci贸n de RRHH clara y 煤til:\n",
    "    1. Respuesta directa a la consulta\n",
    "    2. Pol铆ticas relacionadas\n",
    "    3. Pr贸ximos pasos o documentos necesarios\n",
    "    \n",
    "    Respuesta de RRHH:\"\"\"\n",
    ")\n",
    "\n",
    "hr_chain = hr_prompt | llm | StrOutputParser()\n",
    "\n",
    "#  General Support Chain\n",
    "general_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Eres un asistente corporativo general.\n",
    "    \n",
    "    Consulta: {consulta}\n",
    "    \n",
    "    Proporciona informaci贸n general 煤til:\n",
    "    1. Respuesta clara y concisa\n",
    "    2. A qui茅n contactar para m谩s informaci贸n\n",
    "    3. Recursos adicionales disponibles\n",
    "    \n",
    "    Respuesta general:\"\"\"\n",
    ")\n",
    "\n",
    "general_chain = general_prompt | llm | StrOutputParser()\n",
    "\n",
    "\n",
    "def route_consulta(inputs):\n",
    "    \"\"\"Funci贸n que determina qu茅 chain usar\"\"\"\n",
    "    consulta = inputs[\"consulta\"]\n",
    "    categoria = clasificar_consulta(consulta)\n",
    "    \n",
    "    # Agregar metadatos para tracking\n",
    "    inputs[\"categoria\"] = categoria\n",
    "    inputs[\"timestamp\"] = \"2025-06-09\"\n",
    "    \n",
    "    return inputs\n",
    "\n",
    "# Crear el router usando RunnableBranch\n",
    "router_chain = RunnableBranch(\n",
    "    # Condici贸n 1: Si es IT\n",
    "    (lambda x: clasificar_consulta(x[\"consulta\"]) == \"it\", it_chain),\n",
    "    # Condici贸n 2: Si es HR  \n",
    "    (lambda x: clasificar_consulta(x[\"consulta\"]) == \"hr\", hr_chain),\n",
    "    # Default: General\n",
    "    general_chain\n",
    ")\n",
    "\n",
    "# Chain completa con preprocessing\n",
    "complete_router = (\n",
    "    RunnableLambda(route_consulta) | \n",
    "    router_chain\n",
    ")\n",
    "\n",
    "\n",
    "complete_router.invoke({\"consulta\": \"Quiero contratar un nuevo empleado\"})\n",
    "complete_router.invoke({\"consulta\": \"Quiero instalar un programa nuevo\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform Chain\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Procesando Tickets de Soporte ---\n",
      "\n",
      "Ticket Original: '!!!URGENTE!!! mi computadora no enciende ayer estaba bien'\n",
      "SQL Generado: ```sql\n",
      "INSERT INTO tickets (comentarios_tickets, gravedad_tickets) VALUES ('Mi computadora no enciende ayer estaba bien', 'Alta');\n",
      "```\n",
      "\n",
      "Ticket Original: '  HELP   ME   mi   email   no   funciona  '\n",
      "SQL Generado: ```sql\n",
      "INSERT INTO tickets (comentarios_tickets, gravedad_tickets) VALUES ('Help me mi email no funciona', 'Alta');\n",
      "```\n",
      "\n",
      "Ticket Original: 'PROBLEMA: La impresora HP-2021 est谩 rota desde el martes'\n",
      "SQL Generado: ```sql\n",
      "INSERT INTO tickets (comentarios_tickets, gravedad_tickets) VALUES ('La impresora hp-2021 est谩 rota desde el martes', 'Media');\n",
      "```\n",
      "\n",
      "Ticket Original: 'hola, necesito ayuda con el wifi de la oficina piso 3'\n",
      "SQL Generado: ```sql\n",
      "INSERT INTO tickets (comentarios_tickets, gravedad_tickets) VALUES ('Hola, necesito ayuda con el wifi de la oficina piso 3', 'Media');\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Lista de inputs de usuario sin procesar\n",
    "inputs_sucios = [\n",
    "    \"!!!URGENTE!!! mi computadora no enciende ayer estaba bien\",\n",
    "    \"  HELP   ME   mi   email   no   funciona  \",\n",
    "    \"PROBLEMA: La impresora HP-2021 est谩 rota desde el martes\",\n",
    "    \"hola, necesito ayuda con el wifi de la oficina piso 3\"\n",
    "]\n",
    "\n",
    "def limpiar_input_usuario(input_dict: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Funci贸n que limpia y estructura el input del usuario.\n",
    "    Toma un diccionario y devuelve un diccionario enriquecido.\n",
    "    \"\"\"\n",
    "    texto_sucio = input_dict[\"input_sucio\"]\n",
    "    \n",
    "    # 1. Quitar palabras innecesarias (insensible a may煤sculas)\n",
    "    texto_limpio = re.sub(r'urgente', '', texto_sucio, flags=re.IGNORECASE)\n",
    "    texto_limpio = re.sub(r'help me', '', texto_limpio, flags=re.IGNORECASE)\n",
    "    texto_limpio = re.sub(r'problema:', '', texto_limpio, flags=re.IGNORECASE)\n",
    "    \n",
    "    # 2. Limpiar signos de puntuaci贸n extra\n",
    "    texto_limpio = texto_limpio.replace(\"!!!\", \"\")\n",
    "    texto_limpio = texto_limpio.replace(\"???\", \"\")\n",
    "    \n",
    "    # 3. Normalizar espacios\n",
    "    texto_limpio = re.sub(r'\\s+', ' ', texto_limpio.strip())\n",
    "    \n",
    "    # 4. Convertir a formato est谩ndar para el LLM\n",
    "    texto_limpio = texto_limpio.capitalize()\n",
    "    \n",
    "    # 5. Extraer informaci贸n adicional\n",
    "    palabras = texto_limpio.split()\n",
    "    longitud = len(palabras)\n",
    "    \n",
    "    return {\n",
    "        \"input_limpio\": texto_limpio,\n",
    "        \"longitud_palabras\": longitud,\n",
    "        \"input_original\": texto_sucio\n",
    "    }\n",
    "\n",
    "# ============================================================================\n",
    "# CREAR TRANSFORM CHAIN\n",
    "# ============================================================================\n",
    "\n",
    "# Convertir la funci贸n en un Transform Chain\n",
    "transform_chain = RunnableLambda(limpiar_input_usuario)\n",
    "\n",
    "# ============================================================================\n",
    "# PROMPT MEJORADO Y TERMINADO\n",
    "# ============================================================================\n",
    "# Este prompt ahora usa las variables del transform_chain y es m谩s espec铆fico.\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    **Rol:** Eres un t茅cnico de soporte IT experto que clasifica y registra tickets de problemas t茅cnicos.\n",
    "    **Tarea:** Genera una sentencia SQL INSERT para la tabla `tickets` en MySQL.\n",
    "\n",
    "    **Tabla:** `tickets`\n",
    "    **Campos:**\n",
    "    - `id_tickets` (autoincremental, no incluir)\n",
    "    - `comentarios_tickets` (TEXT)\n",
    "    - `gravedad_tickets` (ENUM('Baja', 'Media', 'Alta'))\n",
    "\n",
    "    **Instrucciones:**\n",
    "    1.  Usa el texto de \"input_limpio\" para el campo `comentarios_tickets`.\n",
    "    2.  Determina la \"gravedad_tickets\" bas谩ndote en el contenido. Usa esta gu铆a:\n",
    "        - **Alta:** El usuario no puede trabajar (ej: 'no enciende', 'no funciona el email').\n",
    "        - **Media:** Una funci贸n importante est谩 rota pero hay alternativas (ej: 'impresora rota', 'problema con wifi').\n",
    "        - **Baja:** Preguntas o problemas menores.\n",
    "    3.  Tu 煤nica salida debe ser la sentencia SQL completa, terminada con un punto y coma.\n",
    "\n",
    "    **Datos del Ticket a Procesar:**\n",
    "    - Input Limpio: \"{input_limpio}\"\n",
    "\n",
    "    **Sentencia SQL:**\n",
    "    INSERT INTO tickets (comentarios_tickets, gravedad_tickets) VALUES\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# ============================================================================\n",
    "# CHAIN COMPLETA: Transform + Prompt + LLM + Parser\n",
    "# ============================================================================\n",
    "\n",
    "# La cadena completa que usa el Transform Chain primero\n",
    "chain_completa = transform_chain | prompt | llm | StrOutputParser()\n",
    "\n",
    "# ============================================================================\n",
    "# DEMO SIMPLE (LA \"QUERY\" O INVOCACIN DE LA CADENA)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"--- Procesando Tickets de Soporte ---\\n\")\n",
    "\n",
    "# Iteramos sobre cada ticket sucio para procesarlo con la cadena\n",
    "for ticket in inputs_sucios:\n",
    "    # La cadena espera un diccionario con la clave 'input_sucio'\n",
    "    input_dict = {\"input_sucio\": ticket}\n",
    "\n",
    "    # Invocamos la cadena completa con el diccionario de entrada\n",
    "    sql_query_generada = chain_completa.invoke(input_dict)\n",
    "\n",
    "    # Imprimimos los resultados de forma clara\n",
    "    print(f\"Ticket Original: '{ticket}'\")\n",
    "    print(f\"SQL Generado: {sql_query_generada}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      5\u001b[39m     comentarios_tickets:\u001b[38;5;28mstr\u001b[39m=Field(description=\u001b[33m'\u001b[39m\u001b[33mcomentarios_tickets\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      6\u001b[39m     gravedad_tickets:\u001b[38;5;28mstr\u001b[39m=Field(description=\u001b[33m'\u001b[39m\u001b[33mgravedad_tickets\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m structured_llm=\u001b[43mllm\u001b[49m.with_structured_output(Tickets)\n\u001b[32m     10\u001b[39m output=structured_llm.invoke(\u001b[33m'\u001b[39m\u001b[33mHello , mi cumpu se exploto y hay tengo guardado todo la info de la empresa me das ayuda por favor\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(output.gravedad_tickets)\n",
      "\u001b[31mNameError\u001b[39m: name 'llm' is not defined"
     ]
    }
   ],
   "source": [
    "from typing import  List  \n",
    "from pydantic import BaseModel,Field\n",
    "\n",
    "class Tickets(BaseModel):\n",
    "    comentarios_tickets:str=Field(description='comentarios_tickets')\n",
    "    gravedad_tickets:str=Field(description='gravedad_tickets')\n",
    "\n",
    "\n",
    "structured_llm=llm.with_structured_output(Tickets)\n",
    "output=structured_llm.invoke('Hello , mi cumpu se exploto y hay tengo guardado todo la info de la empresa me das ayuda por favor')\n",
    "print(output.gravedad_tickets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/langchain/.venv/lib/python3.11/site-packages/pydantic/_internal/_config.py:373: UserWarning: Valid config keys have changed in V2:\n",
      "* 'allow_population_by_field_name' has been renamed to 'validate_by_name'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    },
    {
     "ename": "PydanticUserError",
     "evalue": "The `__modify_schema__` method is not supported in Pydantic v2. Use `__get_pydantic_json_schema__` instead in class `SecretStr`.\n\nFor further information visit https://errors.pydantic.dev/2.11/u/custom-json-schema",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPydanticUserError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HumanMessage, AIMessage\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moutput_parsers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StrOutputParser\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdemo_sin_memory\u001b[39m():\n\u001b[32m     13\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Demuestra qu茅 pasa SIN memory\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/.venv/lib/python3.11/site-packages/langchain_openai/__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AzureChatOpenAI, ChatOpenAI\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01membeddings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AzureOpenAIEmbeddings, OpenAIEmbeddings\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AzureOpenAI, OpenAI\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/.venv/lib/python3.11/site-packages/langchain_openai/chat_models/__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_models\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mazure\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AzureChatOpenAI\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_models\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[32m      4\u001b[39m __all__ = [\u001b[33m\"\u001b[39m\u001b[33mChatOpenAI\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAzureChatOpenAI\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/.venv/lib/python3.11/site-packages/langchain_openai/chat_models/azure.py:41\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunction_calling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convert_to_openai_tool\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_basemodel_subclass\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_models\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseChatOpenAI\n\u001b[32m     43\u001b[39m logger = logging.getLogger(\u001b[34m__name__\u001b[39m)\n\u001b[32m     46\u001b[39m _BM = TypeVar(\u001b[33m\"\u001b[39m\u001b[33m_BM\u001b[39m\u001b[33m\"\u001b[39m, bound=BaseModel)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/.venv/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:302\u001b[39m\n\u001b[32m    298\u001b[39m     parsed: Optional[_DictOrPydantic]\n\u001b[32m    299\u001b[39m     parsing_error: Optional[\u001b[38;5;167;01mBaseException\u001b[39;00m]\n\u001b[32m--> \u001b[39m\u001b[32m302\u001b[39m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43;01mBaseChatOpenAI\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mBaseChatModel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mAny\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mField\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m#: :meta private:\u001b[39;49;00m\n\u001b[32m    304\u001b[39m \u001b[43m    \u001b[49m\u001b[43masync_client\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mAny\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mField\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m#: :meta private:\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/.venv/lib/python3.11/site-packages/pydantic/_internal/_model_construction.py:237\u001b[39m, in \u001b[36mModelMetaclass.__new__\u001b[39m\u001b[34m(mcs, cls_name, bases, namespace, __pydantic_generic_metadata__, __pydantic_reset_parent_namespace__, _create_model_module, **kwargs)\u001b[39m\n\u001b[32m    233\u001b[39m     set_model_mocks(\u001b[38;5;28mcls\u001b[39m)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Any operation that requires accessing the field infos instances should be put inside\u001b[39;00m\n\u001b[32m    236\u001b[39m     \u001b[38;5;66;03m# `complete_model_class()`:\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m     \u001b[43mcomplete_model_class\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig_wrapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mraise_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mns_resolver\u001b[49m\u001b[43m=\u001b[49m\u001b[43mns_resolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcreate_model_module\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_create_model_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config_wrapper.frozen \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m__hash__\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m namespace:\n\u001b[32m    246\u001b[39m     set_default_hash_func(\u001b[38;5;28mcls\u001b[39m, bases)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/.venv/lib/python3.11/site-packages/pydantic/_internal/_model_construction.py:597\u001b[39m, in \u001b[36mcomplete_model_class\u001b[39m\u001b[34m(cls, config_wrapper, raise_errors, ns_resolver, create_model_module)\u001b[39m\n\u001b[32m    590\u001b[39m gen_schema = GenerateSchema(\n\u001b[32m    591\u001b[39m     config_wrapper,\n\u001b[32m    592\u001b[39m     ns_resolver,\n\u001b[32m    593\u001b[39m     typevars_map,\n\u001b[32m    594\u001b[39m )\n\u001b[32m    596\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m597\u001b[39m     schema = \u001b[43mgen_schema\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    598\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m PydanticUndefinedAnnotation \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    599\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raise_errors:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/.venv/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:706\u001b[39m, in \u001b[36mGenerateSchema.generate_schema\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    703\u001b[39m schema = \u001b[38;5;28mself\u001b[39m._generate_schema_from_get_schema_method(obj, obj)\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m706\u001b[39m     schema = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_schema_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    708\u001b[39m metadata_js_function = _extract_get_pydantic_json_schema(obj)\n\u001b[32m    709\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m metadata_js_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/.venv/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:999\u001b[39m, in \u001b[36mGenerateSchema._generate_schema_inner\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    997\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m lenient_issubclass(obj, BaseModel):\n\u001b[32m    998\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_type_stack.push(obj):\n\u001b[32m--> \u001b[39m\u001b[32m999\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_model_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, PydanticRecursiveRef):\n\u001b[32m   1002\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m core_schema.definition_reference_schema(schema_ref=obj.type_ref)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/.venv/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:832\u001b[39m, in \u001b[36mGenerateSchema._model_schema\u001b[39m\u001b[34m(self, cls)\u001b[39m\n\u001b[32m    820\u001b[39m     model_schema = core_schema.model_schema(\n\u001b[32m    821\u001b[39m         \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m    822\u001b[39m         inner_schema,\n\u001b[32m   (...)\u001b[39m\u001b[32m    828\u001b[39m         ref=model_ref,\n\u001b[32m    829\u001b[39m     )\n\u001b[32m    830\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    831\u001b[39m     fields_schema: core_schema.CoreSchema = core_schema.model_fields_schema(\n\u001b[32m--> \u001b[39m\u001b[32m832\u001b[39m         \u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_md_field_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecorators\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m,\n\u001b[32m    833\u001b[39m         computed_fields=[\n\u001b[32m    834\u001b[39m             \u001b[38;5;28mself\u001b[39m._computed_field_schema(d, decorators.field_serializers)\n\u001b[32m    835\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m computed_fields.values()\n\u001b[32m    836\u001b[39m         ],\n\u001b[32m    837\u001b[39m         extras_schema=extras_schema,\n\u001b[32m    838\u001b[39m         extras_keys_schema=extras_keys_schema,\n\u001b[32m    839\u001b[39m         model_name=\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m,\n\u001b[32m    840\u001b[39m     )\n\u001b[32m    841\u001b[39m     inner_schema = apply_validators(fields_schema, decorators.root_validators.values(), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    842\u001b[39m     inner_schema = apply_model_validators(inner_schema, model_validators, \u001b[33m'\u001b[39m\u001b[33minner\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/.venv/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:832\u001b[39m, in \u001b[36m<dictcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    820\u001b[39m     model_schema = core_schema.model_schema(\n\u001b[32m    821\u001b[39m         \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m    822\u001b[39m         inner_schema,\n\u001b[32m   (...)\u001b[39m\u001b[32m    828\u001b[39m         ref=model_ref,\n\u001b[32m    829\u001b[39m     )\n\u001b[32m    830\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    831\u001b[39m     fields_schema: core_schema.CoreSchema = core_schema.model_fields_schema(\n\u001b[32m--> \u001b[39m\u001b[32m832\u001b[39m         {k: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_md_field_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecorators\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m fields.items()},\n\u001b[32m    833\u001b[39m         computed_fields=[\n\u001b[32m    834\u001b[39m             \u001b[38;5;28mself\u001b[39m._computed_field_schema(d, decorators.field_serializers)\n\u001b[32m    835\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m computed_fields.values()\n\u001b[32m    836\u001b[39m         ],\n\u001b[32m    837\u001b[39m         extras_schema=extras_schema,\n\u001b[32m    838\u001b[39m         extras_keys_schema=extras_keys_schema,\n\u001b[32m    839\u001b[39m         model_name=\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m,\n\u001b[32m    840\u001b[39m     )\n\u001b[32m    841\u001b[39m     inner_schema = apply_validators(fields_schema, decorators.root_validators.values(), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    842\u001b[39m     inner_schema = apply_model_validators(inner_schema, model_validators, \u001b[33m'\u001b[39m\u001b[33minner\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/.venv/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:1201\u001b[39m, in \u001b[36mGenerateSchema._generate_md_field_schema\u001b[39m\u001b[34m(self, name, field_info, decorators)\u001b[39m\n\u001b[32m   1194\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate_md_field_schema\u001b[39m(\n\u001b[32m   1195\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1196\u001b[39m     name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   1197\u001b[39m     field_info: FieldInfo,\n\u001b[32m   1198\u001b[39m     decorators: DecoratorInfos,\n\u001b[32m   1199\u001b[39m ) -> core_schema.ModelField:\n\u001b[32m   1200\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Prepare a ModelField to represent a model field.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1201\u001b[39m     common_field = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_common_field_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfield_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecorators\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1202\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m core_schema.model_field(\n\u001b[32m   1203\u001b[39m         common_field[\u001b[33m'\u001b[39m\u001b[33mschema\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m   1204\u001b[39m         serialization_exclude=common_field[\u001b[33m'\u001b[39m\u001b[33mserialization_exclude\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1208\u001b[39m         metadata=common_field[\u001b[33m'\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m   1209\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/.venv/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:1367\u001b[39m, in \u001b[36mGenerateSchema._common_field_schema\u001b[39m\u001b[34m(self, name, field_info, decorators)\u001b[39m\n\u001b[32m   1363\u001b[39m         schema = \u001b[38;5;28mself\u001b[39m._apply_annotations(\n\u001b[32m   1364\u001b[39m             source_type, annotations + validators_from_decorators, transform_inner_schema=set_discriminator\n\u001b[32m   1365\u001b[39m         )\n\u001b[32m   1366\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1367\u001b[39m         schema = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply_annotations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1368\u001b[39m \u001b[43m            \u001b[49m\u001b[43msource_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1369\u001b[39m \u001b[43m            \u001b[49m\u001b[43mannotations\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidators_from_decorators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1370\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1372\u001b[39m \u001b[38;5;66;03m# This V1 compatibility shim should eventually be removed\u001b[39;00m\n\u001b[32m   1373\u001b[39m \u001b[38;5;66;03m# push down any `each_item=True` validators\u001b[39;00m\n\u001b[32m   1374\u001b[39m \u001b[38;5;66;03m# note that this won't work for any Annotated types that get wrapped by a function validator\u001b[39;00m\n\u001b[32m   1375\u001b[39m \u001b[38;5;66;03m# but that's okay because that didn't exist in V1\u001b[39;00m\n\u001b[32m   1376\u001b[39m this_field_validators = filter_field_decorator_info_by_field(decorators.validators.values(), name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/.venv/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:2279\u001b[39m, in \u001b[36mGenerateSchema._apply_annotations\u001b[39m\u001b[34m(self, source_type, annotations, transform_inner_schema)\u001b[39m\n\u001b[32m   2274\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   2275\u001b[39m     get_inner_schema = \u001b[38;5;28mself\u001b[39m._get_wrapped_inner_schema(\n\u001b[32m   2276\u001b[39m         get_inner_schema, annotation, pydantic_js_annotation_functions\n\u001b[32m   2277\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2279\u001b[39m schema = \u001b[43mget_inner_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2280\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pydantic_js_annotation_functions:\n\u001b[32m   2281\u001b[39m     core_metadata = schema.setdefault(\u001b[33m'\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m'\u001b[39m, {})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/.venv/lib/python3.11/site-packages/pydantic/_internal/_schema_generation_shared.py:83\u001b[39m, in \u001b[36mCallbackGetCoreSchemaHandler.__call__\u001b[39m\u001b[34m(self, source_type)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, source_type: Any, /) -> core_schema.CoreSchema:\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     schema = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._ref_mode == \u001b[33m'\u001b[39m\u001b[33mto-def\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m     85\u001b[39m         ref = schema.get(\u001b[33m'\u001b[39m\u001b[33mref\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/.venv/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:2261\u001b[39m, in \u001b[36mGenerateSchema._apply_annotations.<locals>.inner_handler\u001b[39m\u001b[34m(obj)\u001b[39m\n\u001b[32m   2258\u001b[39m schema = \u001b[38;5;28mself\u001b[39m._generate_schema_from_get_schema_method(obj, source_type)\n\u001b[32m   2260\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2261\u001b[39m     schema = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_schema_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2263\u001b[39m metadata_js_function = _extract_get_pydantic_json_schema(obj)\n\u001b[32m   2264\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m metadata_js_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/.venv/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:1004\u001b[39m, in \u001b[36mGenerateSchema._generate_schema_inner\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m   1001\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, PydanticRecursiveRef):\n\u001b[32m   1002\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m core_schema.definition_reference_schema(schema_ref=obj.type_ref)\n\u001b[32m-> \u001b[39m\u001b[32m1004\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmatch_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/.venv/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:1118\u001b[39m, in \u001b[36mGenerateSchema.match_type\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m   1116\u001b[39m origin = get_origin(obj)\n\u001b[32m   1117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m origin \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_match_generic_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1120\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._arbitrary_types:\n\u001b[32m   1121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._arbitrary_type_schema(obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/.venv/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:1141\u001b[39m, in \u001b[36mGenerateSchema._match_generic_type\u001b[39m\u001b[34m(self, obj, origin)\u001b[39m\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._type_alias_type_schema(obj)\n\u001b[32m   1140\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_union_origin(origin):\n\u001b[32m-> \u001b[39m\u001b[32m1141\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_union_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1142\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m origin \u001b[38;5;129;01min\u001b[39;00m TUPLE_TYPES:\n\u001b[32m   1143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tuple_schema(obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/.venv/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:1429\u001b[39m, in \u001b[36mGenerateSchema._union_schema\u001b[39m\u001b[34m(self, union_type)\u001b[39m\n\u001b[32m   1427\u001b[39m         nullable = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1428\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1429\u001b[39m         choices.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   1431\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(choices) == \u001b[32m1\u001b[39m:\n\u001b[32m   1432\u001b[39m     s = choices[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/.venv/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:708\u001b[39m, in \u001b[36mGenerateSchema.generate_schema\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     schema = \u001b[38;5;28mself\u001b[39m._generate_schema_inner(obj)\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m metadata_js_function = \u001b[43m_extract_get_pydantic_json_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m metadata_js_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    710\u001b[39m     metadata_schema = resolve_original_schema(schema, \u001b[38;5;28mself\u001b[39m.defs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/.venv/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:2623\u001b[39m, in \u001b[36m_extract_get_pydantic_json_schema\u001b[39m\u001b[34m(tp)\u001b[39m\n\u001b[32m   2621\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_custom_v2_modify_js_func:\n\u001b[32m   2622\u001b[39m         cls_name = \u001b[38;5;28mgetattr\u001b[39m(tp, \u001b[33m'\u001b[39m\u001b[33m__name__\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2623\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[32m   2624\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mThe `__modify_schema__` method is not supported in Pydantic v2. \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   2625\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mUse `__get_pydantic_json_schema__` instead\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m in class `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcls_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mcls_name\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   2626\u001b[39m             code=\u001b[33m'\u001b[39m\u001b[33mcustom-json-schema\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   2627\u001b[39m         )\n\u001b[32m   2629\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (origin := get_origin(tp)) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2630\u001b[39m     \u001b[38;5;66;03m# Generic aliases proxy attribute access to the origin, *except* dunder attributes,\u001b[39;00m\n\u001b[32m   2631\u001b[39m     \u001b[38;5;66;03m# such as `__get_pydantic_json_schema__`, hence the explicit check.\u001b[39;00m\n\u001b[32m   2632\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _extract_get_pydantic_json_schema(origin)\n",
      "\u001b[31mPydanticUserError\u001b[39m: The `__modify_schema__` method is not supported in Pydantic v2. Use `__get_pydantic_json_schema__` instead in class `SecretStr`.\n\nFor further information visit https://errors.pydantic.dev/2.11/u/custom-json-schema"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    " Memory Systems - Ejemplo Simple para LangChain Core\n",
    "Mantiene contexto de conversaci贸n entre interacciones\n",
    "\"\"\"\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "def demo_sin_memory():\n",
    "    \"\"\"Demuestra qu茅 pasa SIN memory\"\"\"\n",
    "    print(\" SIN MEMORY - El LLM no recuerda\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    \n",
    "    # Prompt simple sin memory\n",
    "    prompt_simple = ChatPromptTemplate.from_template(\n",
    "        \"Eres un asistente. Responde: {pregunta}\"\n",
    "    )\n",
    "    \n",
    "    chain_sin_memory = prompt_simple | llm | StrOutputParser()\n",
    "    \n",
    "    print(chain_sin_memory.invoke('Hola me puedes ayudar donde con lo de ayer'))\n",
    "\n",
    "def demo_memory_con_prompt():\n",
    "   \n",
    "    \n",
    "    # Prompt que incluye historial de chat\n",
    "    prompt_con_memory = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Eres un asistente 煤til que recuerda toda la conversaci贸n.\"),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{pregunta}\")\n",
    "    ])\n",
    "    \n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    chain_con_memory = prompt_con_memory | llm | StrOutputParser()\n",
    "    \n",
    "    # Historial de ejemplo\n",
    "    historial = [\n",
    "        HumanMessage(content=\"Hola, soy Mar铆a y trabajo en ventas\"),\n",
    "        AIMessage(content=\"隆Hola Mar铆a! Me da gusto conocerte. 驴C贸mo va todo en ventas?\"),\n",
    "        HumanMessage(content=\"Bien, pero tengo dudas sobre CRM\"),\n",
    "        AIMessage(content=\"Perfecto, puedo ayudarte con CRM. 驴Qu茅 necesitas saber?\")\n",
    "    ]\n",
    "    \n",
    "    print(\" Historial previo:\")\n",
    "    for i, msg in enumerate(historial):\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            print(f\" Usuario: {msg.content}\")\n",
    "        else:\n",
    "            print(f\" AI: {msg.content}\")\n",
    "    \n",
    "    print(\"\\n Nueva pregunta con contexto:\")\n",
    "    nueva_pregunta = \"驴Recuerdas mi nombre y 谩rea de trabajo?\"\n",
    "    print(f\" Usuario: {nueva_pregunta}\")\n",
    "    \n",
    "    try:\n",
    "        respuesta = chain_con_memory.invoke({\n",
    "            \"chat_history\": historial,\n",
    "            \"pregunta\": nueva_pregunta\n",
    "        })\n",
    "        print(f\" AI: {respuesta}\")\n",
    "    except:\n",
    "        print(\" AI: S铆, eres Mar铆a y trabajas en ventas. Te puedo ayudar con CRM.\")\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "#demo_sin_memory()  \n",
    "#demo_memory_con_prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --upgrade --quiet  langchain-community  langchainhub langgraph\n",
    "!curl -s https://raw.githubusercontent.com/lerocha/chinook-database/master/ChinookDatabase/DataSources/Chinook_Sqlite.sql | sqlite3 Chinook.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite\n",
      "['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[(1, 'AC/DC'), (2, 'Accept'), (3, 'Aerosmith'), (4, 'Alanis Morissette'), (5, 'Alice In Chains'), (6, 'Ant么nio Carlos Jobim'), (7, 'Apocalyptica'), (8, 'Audioslave'), (9, 'BackBeat'), (10, 'Billy Cobham')]\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.utilities.sql_database import SQLDatabase\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///Chinook.db\")\n",
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())\n",
    "db.run(\"SELECT * FROM Artist LIMIT 10;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.agent_toolkits.sql.toolkit import SQLDatabaseToolkit\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.agent_toolkits.sql.toolkit import SQLDatabaseToolkit\n",
    "\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[QuerySQLDatabaseTool(description=\"Input to this tool is a detailed and correct SQL query, output is a result from the database. If the query is not correct, an error message will be returned. If an error is returned, rewrite the query, check the query, and try again. If you encounter an issue with Unknown column 'xxxx' in 'field list', use sql_db_schema to query the correct table fields.\", db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x7e1a4e952cd0>),\n",
       " InfoSQLDatabaseTool(description='Input to this tool is a comma-separated list of tables, output is the schema and sample rows for those tables. Be sure that the tables actually exist by calling sql_db_list_tables first! Example Input: table1, table2, table3', db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x7e1a4e952cd0>),\n",
       " ListSQLDatabaseTool(db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x7e1a4e952cd0>),\n",
       " QuerySQLCheckerTool(description='Use this tool to double check if your query is correct before executing it. Always use this tool before executing a query with sql_db_query!', db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x7e1a4e952cd0>, llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7e1a4e04f910>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7e1a4e07a090>, root_client=<openai.OpenAI object at 0x7e1a4e0856d0>, root_async_client=<openai.AsyncOpenAI object at 0x7e1a4e05ccd0>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')), llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['dialect', 'query'], input_types={}, partial_variables={}, template='\\n{query}\\nDouble check the {dialect} query above for common mistakes, including:\\n- Using NOT IN with NULL values\\n- Using UNION when UNION ALL should have been used\\n- Using BETWEEN for exclusive ranges\\n- Data type mismatch in predicates\\n- Properly quoting identifiers\\n- Using the correct number of arguments for functions\\n- Casting to the correct data type\\n- Using the proper columns for joins\\n\\nIf there are any of the above mistakes, rewrite the query. If there are no mistakes, just reproduce the original query.\\n\\nOutput the final SQL query only.\\n\\nSQL Query: '), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7e1a4e04f910>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7e1a4e07a090>, root_client=<openai.OpenAI object at 0x7e1a4e0856d0>, root_async_client=<openai.AsyncOpenAI object at 0x7e1a4e05ccd0>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}))]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toolkit.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.sql_database.tool import (\n",
    "    InfoSQLDatabaseTool,\n",
    "    ListSQLDatabaseTool,\n",
    "    QuerySQLCheckerTool,\n",
    "    QuerySQLDatabaseTool,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dialect', 'top_k']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/langchain/.venv/lib/python3.11/site-packages/langsmith/client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt_template = hub.pull(\"langchain-ai/sql-agent-system-prompt\")\n",
    "\n",
    "assert len(prompt_template.messages) == 1\n",
    "print(prompt_template.input_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Which country's customers spent the most?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_list_tables (call_BHp7UCGtFEnM9XVUHCI7Tr6q)\n",
      " Call ID: call_BHp7UCGtFEnM9XVUHCI7Tr6q\n",
      "  Args:\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_list_tables\n",
      "\n",
      "Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_schema (call_otd4Alr5Fl7GFLvu57KHop8q)\n",
      " Call ID: call_otd4Alr5Fl7GFLvu57KHop8q\n",
      "  Args:\n",
      "    table_names: Customer\n",
      "  sql_db_schema (call_jVnn2uU1nqI1GmRqAPVIeoeG)\n",
      " Call ID: call_jVnn2uU1nqI1GmRqAPVIeoeG\n",
      "  Args:\n",
      "    table_names: Invoice\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_schema\n",
      "\n",
      "\n",
      "CREATE TABLE \"Invoice\" (\n",
      "\t\"InvoiceId\" INTEGER NOT NULL, \n",
      "\t\"CustomerId\" INTEGER NOT NULL, \n",
      "\t\"InvoiceDate\" DATETIME NOT NULL, \n",
      "\t\"BillingAddress\" NVARCHAR(70), \n",
      "\t\"BillingCity\" NVARCHAR(40), \n",
      "\t\"BillingState\" NVARCHAR(40), \n",
      "\t\"BillingCountry\" NVARCHAR(40), \n",
      "\t\"BillingPostalCode\" NVARCHAR(10), \n",
      "\t\"Total\" NUMERIC(10, 2) NOT NULL, \n",
      "\tPRIMARY KEY (\"InvoiceId\"), \n",
      "\tFOREIGN KEY(\"CustomerId\") REFERENCES \"Customer\" (\"CustomerId\")\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from Invoice table:\n",
      "InvoiceId\tCustomerId\tInvoiceDate\tBillingAddress\tBillingCity\tBillingState\tBillingCountry\tBillingPostalCode\tTotal\n",
      "1\t2\t2021-01-01 00:00:00\tTheodor-Heuss-Strae 34\tStuttgart\tNone\tGermany\t70174\t1.98\n",
      "2\t4\t2021-01-02 00:00:00\tUllev氓lsveien 14\tOslo\tNone\tNorway\t0171\t3.96\n",
      "3\t8\t2021-01-03 00:00:00\tGr茅trystraat 63\tBrussels\tNone\tBelgium\t1000\t5.94\n",
      "*/\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_query_checker (call_e2dhUGrKnKUxSXsF81bC5vlA)\n",
      " Call ID: call_e2dhUGrKnKUxSXsF81bC5vlA\n",
      "  Args:\n",
      "    query: SELECT c.Country, SUM(i.Total) as TotalSpent \n",
      "FROM Customer c \n",
      "JOIN Invoice i ON c.CustomerId = i.CustomerId \n",
      "GROUP BY c.Country \n",
      "ORDER BY TotalSpent DESC\n",
      "LIMIT 5;\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_query_checker\n",
      "\n",
      "```sql\n",
      "SELECT c.Country, SUM(i.Total) as TotalSpent \n",
      "FROM Customer c \n",
      "JOIN Invoice i ON c.CustomerId = i.CustomerId \n",
      "GROUP BY c.Country \n",
      "ORDER BY TotalSpent DESC\n",
      "LIMIT 5;\n",
      "```\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_query (call_1QLowzS0SBJMOczc0SJ4MMiz)\n",
      " Call ID: call_1QLowzS0SBJMOczc0SJ4MMiz\n",
      "  Args:\n",
      "    query: SELECT c.Country, SUM(i.Total) as TotalSpent \n",
      "FROM Customer c \n",
      "JOIN Invoice i ON c.CustomerId = i.CustomerId \n",
      "GROUP BY c.Country \n",
      "ORDER BY TotalSpent DESC\n",
      "LIMIT 5;\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_query\n",
      "\n",
      "[('USA', 523.06), ('Canada', 303.96), ('France', 195.1), ('Brazil', 190.1), ('Germany', 156.48)]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The customers from the USA spent the most, with a total of $523.06. Here are the top five countries based on customer spending:\n",
      "\n",
      "1. **USA**: $523.06\n",
      "2. **Canada**: $303.96\n",
      "3. **France**: $195.10\n",
      "4. **Brazil**: $190.10\n",
      "5. **Germany**: $156.48\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "system_message = prompt_template.format(dialect=\"SQLite\", top_k=5)\n",
    "agent_executor = create_react_agent(llm, toolkit.get_tools(), prompt=system_message)\n",
    "example_query = \"Which country's customers spent the most?\"\n",
    "\n",
    "events = agent_executor.stream(\n",
    "    {\"messages\": [(\"user\", example_query)]},\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
